{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a811d4ac-5ec3-455e-8333-af086fc8eea6",
   "metadata": {},
   "source": [
    "# 2.5 첫 번째 예제 다시 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91827a0f-60dc-4402-b7d2-044ac364811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07856099-a985-4dca-8c71-ad0c521ed3b2",
   "metadata": {},
   "source": [
    "입력 이미지의 데이터 타입은 float32로, 훈련 데이터는 (60000, 784) 크기, 테스트 데이터는 (10000, 784) 크기의 넘파이 배열로 저장됩니다.\n",
    "\n",
    "우리가 사용할 신경망입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe90587a-8b7c-4098-917b-d240860a3ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5389bf68-acfe-488d-9c40-aa8725d9888f",
   "metadata": {},
   "source": [
    "이 네트워크는 2개의 Dense 층이 연결되어 있고 각 층은 가중치 텐서를 포함하여 입력 데이터에 대한 몇 개의 간단한 텐서 연산을 적용합니다.\n",
    "\n",
    "이제 네트워크를 컴파일하는 단계입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7da5a9cd-669f-4caa-a295-00e3ba5484d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec204bd-3bec-4b23-a965-9492a63102da",
   "metadata": {},
   "source": [
    "categorical_crossentropy는 손실 함수입니다. 가중치 텐서를 학습하기 위한 피드백 신호로 사용되며 훈련하는 동안 최소화됩니다. 미니 배치 확률적 경사 하강법을 통해 손실이 감소됩니다. 경사 하강법을 적용하는 구체적인 방식은 첫 번째 매개변수로 전달된 rmsprop 옵티마이저에 의해 결정됩니다.\n",
    "\n",
    "마치막으로 훈련 반복입니다."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bbc38ce-7783-495b-864b-2a369c5ffb56",
   "metadata": {},
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e1b820-01eb-488d-84da-aa3c5662d9d1",
   "metadata": {},
   "source": [
    "fit 메서드를 호출했을 때 다음과 같은 일이 일어납니다. 네트워크가 128개 샘플씩 미니 배치로 훈련 데이터를 다섯 번 반복합니다(전체 훈련 데이터에 수행되는 각 반복을 에포크(epoch)라고 합니다). 각 반복마다 네트워크가 배치에서 손실에 대한 가중치의 그래디언트를 계산하고 그에 맞추어 가중치를 업데이트합니다. 다섯 번의 에포크 동안 네트워크는 2345번의 그래디언트 업데이트를 수행할 것입니다(에포크마다 469번)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e91187-ca0c-4bd8-b98e-89a16c580829",
   "metadata": {},
   "source": [
    "# 2.6 요약"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bac75e4-9e9c-4535-92df-e5c87b875527",
   "metadata": {},
   "source": [
    "- 학습(Learning)은 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화 하는 모델 파라미터의 조합을 찾는 것을 의미합니다.\n",
    "- 데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행됩니다. 네트워크의 파라미터는 그래디언트의 반대 방향으로 조금씩(학습률에 의해 정의된 크긔만큼) 움직입니다.\n",
    "- 전체 학습 과정은 신경망이 미분 가능한 텐서 연산으로 연결되어 있기 때문에 가능합니다. 현재 파라미터와 배치 데이터를 그래디언트 값에 매핑해 주는 그래디언트 함수를 구성하기 위해 미분의 연쇄 법칙을 사용합니다.\n",
    "- 이어지는 장에서 자주 보게 될 두 가지 핵심 개념은 손실과 옵티마이저입니다. 이 두 가지는 네트워크에 데이터를 주입하기 전에 정의되어야 합니다.\n",
    "- 손실은 훈련하는 동안 최소화해야 할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용합니다.\n",
    "- 옵티마이저는 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의합니다. 예를 들어 RMSProp 옵티마이저, 모멘텀을 사용한 SGD 등입니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
