{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70fad6c-178d-4540-9391-6cabe543a506",
   "metadata": {},
   "source": [
    "# 3.5 뉴스 기사 분류- 다중 분류 문제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3042aba7-7896-4e40-8ebd-86fc57c158e7",
   "metadata": {},
   "source": [
    "이 절에서 로이터 뉴스를 46개의 상호 배타적인 토픽으로 분류하는 신경망을 만들어 보겠습니다. 클래스가 많기 때문에 이 문제는 다중 분류(multiclass classification)의 예입니다. 좀 더 정확히 말하면 단일 레이블 다중 분류(single-label, multiclass classification) 문제입니다.\n",
    "\n",
    "### 3.5.1 로이터 데이터셋\n",
    "#### 코드 3-12 로이터 데이터셋 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfc8ac97-d116-4457-bebb-22256d42ebde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "\u001b[1m2110848/2110848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd7771c-4b83-4d7b-9335-2e438e562524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d105805c-4d31-46dd-95e0-a27ff88b929c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9214f225-7887-4e3d-acd7-0941b91fb2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 245,\n",
       " 273,\n",
       " 207,\n",
       " 156,\n",
       " 53,\n",
       " 74,\n",
       " 160,\n",
       " 26,\n",
       " 14,\n",
       " 46,\n",
       " 296,\n",
       " 26,\n",
       " 39,\n",
       " 74,\n",
       " 2979,\n",
       " 3554,\n",
       " 14,\n",
       " 46,\n",
       " 4689,\n",
       " 4329,\n",
       " 86,\n",
       " 61,\n",
       " 3499,\n",
       " 4795,\n",
       " 14,\n",
       " 61,\n",
       " 451,\n",
       " 4329,\n",
       " 17,\n",
       " 12]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd755bb-cd13-489b-9fbe-035192f4f4c2",
   "metadata": {},
   "source": [
    "#### 코드 3-13 로이터 데이터셋을 텍스트로 디코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f637425d-6e1c-4d7d-ad0d-1ab70e3314bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "decoded_newswire = ' '.join([reverse_word_index.get(i - 3, '?') for i in train_data[0]])\n",
    "train_labels[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d599b3fb-95d5-45e0-8de3-33f742cef368",
   "metadata": {},
   "source": [
    "### 3.5.2 데이터 준비\n",
    "#### 코드 3-14 데이터 인코딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5e362c-8f6f-4c8c-8271-84f8671d3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6cb090-b91f-49e9-b79c-48bf283a3a92",
   "metadata": {},
   "source": [
    "레이블을 벡터로 바꾸는 방법은 두 가지 입니다. 레이블의 리스트를 정수 텐서로 변환하는 것과 원-핫 인코딩을 사용하는 것입니다. 원-핫 인코딩이 범주형 데이터에 널리 사용되기 때문에 범주형 인코딩(categorical encoding)이라고도 부릅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91c51979-9103-49b8-abf8-999de3ecf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = to_one_hot(train_labels)\n",
    "one_hot_test_labels = to_one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f5573-59f8-4d37-8a68-742cb2b525f3",
   "metadata": {},
   "source": [
    "MNIST 예제에서 이미 보았듯이 케라스에는 이를 위한 내장 함수가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6095ac6-1ee6-474e-8b23-696eb3320871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.utils.np_utils import to_categorical\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e3fbb7-4c63-4eeb-9110-4eff766e2337",
   "metadata": {},
   "source": [
    "### 3.5.3 모델 구성\n",
    "이전 예제에서 16차원을 가진 중간층을 사용했지만 16차원 공간은 64개의 클래스를 구분하기에 너무 제약이 많을 것 같습니다. 이렇게 규모가 작은 층은 유용한 정보를 완전히 잃게 되는 정보의 병목지점처럼 동작할 수 있습니다.\n",
    "이런 이유로 좀 더 규모가 큰 층을 사용하겠습니다. 64개의 유닛을 사용해 보죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3044a570-3be2-4b80-b5b3-9cb31bc810e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
