{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596c856b-6072-4195-bdec-e74dfb226978",
   "metadata": {},
   "source": [
    "# 4.5 보편적인 머신 러닝 작업 흐름"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577aa08a-52e5-488d-9e4c-0eb5c68a92eb",
   "metadata": {},
   "source": [
    "### 4.5.1 문제 정의와 데이터셋 수집\n",
    "먼저 주어진 문제를 정의해야 합니다.\n",
    "- 입력 데이터는 무엇인가요? 어떤 것을 예측하려고 하나요?\n",
    "- 당면한 문제가 어떤 종류인가요? 이진 분류인가요? 다중 분류인가요? 스칼라 회귀인가요? 벡터 회귀인가요? 다중 레이블 다중 분류인가요? 아니면 군집, 생성 또는 강화 학습 같은 다른 문제인가요?\n",
    "\n",
    "입력과 출력이 무엇인지와 어떤 데이터를 사용할 것인지 알기 전까지는 다음 단계로 넘어갈 수 없습니다. 이 단계에서 가설을 세워야 합니다.\n",
    "- 주어진 입력으로 출력을 예측할 수 있다고 가설을 세웁니다.\n",
    "- 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세웁니다.\n",
    "\n",
    "모델이 작동하기 전까지 이는 가설에 불과합니다. 검증될지 아닐지 기다려 보아야 합니다. 모든 문제가 해결되지는 않습니다. 입력 X와 타깃 Y의 샘플을 수집했다고 X에 Y를 예측하기에 충분한 정보가 있는 것은 아닙니다.\n",
    "\n",
    "출기 어려운 종류의 문제는 시간에 따라변하는 문제(nonstationary problem)입니다. 이런 경우에 최근의 데이터로 주기적으로 모델을 다시 훈련하거나 시간 분포에 맞게 데이터를 수집하여 시간에 따라 변하지 않는 문제로 바꿉니다.\n",
    "\n",
    "머신 러닝은 훈련 데이터에 있는 패턴을 기억하기 위해서만 사용한다는 것을 유념하세요. 미래를 예측하기 위해 과거 데이터에서 훈련한 머신 러닝을 사용하는 것은 미래가 과거처럼 움직인다고 가정한 것입니다. 사실 대부분 그렇지는 않습니다.\n",
    "\n",
    "### 4.5.2 성공 지표 선택\n",
    "성공하기 위해서는 성공은 무엇인가를 정의해야 합니다. 정확도일까요? 정밀도나 재현율일까요?\n",
    "\n",
    "클래스 분포가 균일한 분류 문제에서는 정확도와 ROC AUC가 일반적인 지표입니다. 클래스 분포가 균일하지 않은 문제에서는 정밀도와 재현율을 사용할 수 있습니다. 랭킹 문제나 다중 레이블 문제에는 평균 정밀도를 사용할 수 있습니다. 성공을 측정하기 위해 자신만의 지표를 정의하는 일은 일반적이지 않습니다. 머신 러닝의 다양한 성공 지표가 여러 가지 종류의 문제에 어떻게 관련되어 있는지 알고 싶다면 캐글([https://kaggle.com](https://kaggle.com))의 데이터 과학 경연 대회를 살펴보는 것이 도움이 됩니다.\n",
    "\n",
    "### 4.5.3 평가 방법 선택\n",
    "잘 알려진 세가 평가 방식\n",
    "- 홀드아웃 검증 세트 분리: 데이터가 풍부할 때 사용합니다.\n",
    "- K-겹 교차 검증: 홀드아웃 검증을 사용하기에 샘플의 수가 너무 적을때 사용합니다.\n",
    "- 반복 K-겹 교차 검증: 데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용합니다.\n",
    "\n",
    "### 4.5.4 데이터 준비\n",
    "- 앞서 보았듯이 데이터는 텐서로 구성됩니다.\n",
    "- 이 텐서에 있는 값은 일반적으로 작은 값으로 스케일 조정되어 있습니다. 예를 들어 [-1, 1] 이나 [0, 1] 범위입니다.\n",
    "- 특성마다 범위가 다르면(여러 종류의 값으로 이루어진 데이터라면) 정규화해야 합니다.\n",
    "- 특성 공학을 수행할 수 있습니다. 특히 데이터가 적을 때입니다.\n",
    "\n",
    "### 4.5.5 기본보다 나은 모델 훈련하기\n",
    "이 단계의 목표는 통계적 검정력(statistical power)을 달성하는 것입니다. 즉 아주 단순한 모델보다 나은 수준의 작은 모델을 개발합니다.\n",
    "\n",
    "통계적 검정력을 달성하는 것이 항상 가능하지는 않습니다. 여러 개의 타당성 있는 네트워크 구조를 시도해보고 무작위로 예측하는 모델보다 낫지 않다면 입력 데이터에 존재하지 않는 것을 얻으려고 한다는 신호일 것입니다. 2개의 가설이 있다는 것을 기억하세요.\n",
    "- 주어진 입력으로 출력을 예측할 수 있다고 가설을 세웁니다.\n",
    "- 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있다고 가설을 세웁니다.\n",
    "\n",
    "이 가설이 잘못된 것일 수 있습니다. 이때는 기획부터 다시 해야합니다.\n",
    "\n",
    "일이 잘 진행된다고 가정하면 첫 번째 모델을 만들기 위해 세 가지 중요한 선택을 해야 합니다.\n",
    "- 마지막 층의 활성화 함수: 네트워크의 출력에 필요한 제한을 가합니다. 예를 들어 IMDB 분류 예는 마지막 층에 시그모이드 함수를 사용합니다. 회귀 예에서는 마지막 층에 활성화 함수를 사용하지 않습니다.\n",
    "- 손실 함수: 풀려고 하는 문제의 종류에 적합해야 합니다. 예를 들어 IMDB 예제는 binary_crossentropy를 사용하고, 회귀 예제는 mse를 사용하는 식입니다.\n",
    "- 최적화 설정: 어떤 옵티마이저를 사용하나요? 학습률은 얼마인가요? 대부분의 경우 rmsprop과 기본 학습률을 사용하는 것이 무난합니다.\n",
    "\n",
    "손실 함수의 선택에 대해서 언급할 것은 주어진 문제의 성공 지표를 직접 최적화하는 것이 항상 가능하지 않다는 점입니다.\n",
    "\n",
    "<img src=\"img/4_loss_function.jpeg\" alt=\"4_loss_function\" width=\"600px\" />\n",
    "\n",
    "### 4.5.6 몸집 키우기: 과대적합 모델 구축\n",
    "통계적 검정력을 가진 모델을 얻었다면 이제 모델이 충분히 성능을 내는지 질문해 보아야 합니다. 주어진 문제를 적절히 모델링하기에 충분한 층과 파라미터가 있나요? 머신 러닝은 최적화와 일반화 사이의 줄다리기라는 점을 기억하세요. 과소적합과 과대적합 사이, 즉 과소용량과 과대용량의 경계에 적절히 위치한 모델이 이상적입니다. 이 경계가 어디에 위치하는지 찾기 위해서는 먼저 지나쳐 보아야 합니다.\n",
    "\n",
    "얼마나 큰 모델을 만들어야 하는지 알기 위해서는 과대적합된 모델을 만들어야 합니다. 이는 아주 쉽습니다.\n",
    "1. 층을 추가합니다.\n",
    "2. 층의 크기를 키웁니다.\n",
    "3. 더 많은 에포크 동안 훈련합니다.\n",
    "\n",
    "훈련과 검증 지표는 물론 항상 훈련 손실과 검증 손실을 모니터링하세요. 검증 데이터에서 모델 성능이 감소하기 시작했을 때 과대적합에 도달한 것입니다.\n",
    "\n",
    "### 4.5.7 모델 규제와 하이퍼파라미터 튜닝\n",
    "이 단계가 대부분의 시간을 차지합니다.\n",
    "- 드롭아웃을 추가합니다.\n",
    "- 층을 추가하거나 제거해서 다른 구조를 시도해 봅니다.\n",
    "- L1이나 L2 또는 두 가지 모두 추가합니다.\n",
    "- 최적의 설정을 찾기 위해 하이퍼파라미터를 바꾸어 시도해 봅니다(층의 유닛 수나 옵티마이저의 학습률 등).\n",
    "- 선택적으로 특성 공학을 시도해 봅니다. 새로운 특성을 추가하거나 유용하지 않을 것 같은 특성을 제거합니다.\n",
    "\n",
    "다음 사항을 유념하세요. 검증 과정에서 얻은 피드백을 사용하여 모델을 튜닝할 때마다 검증 과정에 대한 정보를 모델에 누설하고 있다는 것입니다.\n",
    "\n",
    "만족할 만한 모델 설정을 얻었다면 가용한 모든 데이터(훈련 데이터와 검증 데이터)를 사용해서 제품에 투입할 최종 모델을 훈련시킵니다. 그리고 마지막에 딱 한 번 테스트 세트에서 평가합니다. 테스트 세트의 성능이 검증 데이터에서 측정한 것보다 많이 나쁘다면, 검증 과정에 전혀 신뢰성이 없거나 모델의 하이퍼파라미터를 튜닝하는 동안 검증 데이터에 과대적합된 것입니다. 이런 경우에는 좀 더 신뢰할 만한 평가 방법으로 바꾸는 것이 좋습니다(반복 K-겹 교차 검증)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
