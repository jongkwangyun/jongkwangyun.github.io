{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cfe91dc",
   "metadata": {},
   "source": [
    "# 7.1 Sequential 모델을 넘어서- 케라스의 함수형 API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af02811",
   "metadata": {},
   "source": [
    "지금까지 이 책에서 소개한 모든 신경망은 Sequential 모델을 사용하여 만들었습니다. Sequential 모델은 네트워크의 입력과 출력이 하나라고 가정합니다. 이 모델은 층알 차례대로 쌓아 구성합니다.\n",
    "\n",
    "많은 경우에 이런 가정이 적절합니다. 하지만 이런 가정이 맞지 않는 경우도 많습니다. 일부 네트워크는 개별 입력이 여러 개 필요하거나 출력이 여러 개 필요합니다. 층을 차례대로 쌓지 않고 층 사이를 연결하여 그래프처럼 만드는 네트워크도 있습니다.\n",
    "\n",
    "여러 경우에 다중 입력 모델, 다중 출력 모델, 그래프 구조를 띤 모델이 필요하지만 케라스의 Sequential 클래스를 사용해서는 만들지 못합니다. 케라스에는 훨씬 더 일반적이고 유연한 다른 방법인 함수형 API가 있습니다.\n",
    "\n",
    "### 7.1.1 함수형 API 소개\n",
    "\n",
    "함수형 API(functional API)에서는 직접 텐서들의 입출력을 다룹니다.\n",
    "\n",
    "```python\n",
    "from keras import Input, layers\n",
    "\n",
    "input_tensor = Input(shape=(32,))  # 텐서\n",
    "dense = layers.Dense(32, activation='relu')  # 함수처럼 사용하기 위해 층 객체를 만듭니다.\n",
    "\n",
    "output_tensor = dense(input_tensor)  # 텐서와 함께 층을 호출하면 텐서를 반환합니다.\n",
    "```\n",
    "\n",
    "간단한 예를 통해 Sequential 모델과 함수형 API로 만든 동일한 모델을 나란히 비교해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e424f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "d:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:469: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "d:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:470: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "d:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:471: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "d:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:472: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "d:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:473: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "d:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:476: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "seq_model = Sequential()  # 익숙한 Sequential 모델입니다.\n",
    "seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "seq_model.add(layers.Dense(32, activation='relu'))\n",
    "seq_model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# 함수형 API로 만든 모델입니다.\n",
    "input_tensor = Input(shape=(64,))\n",
    "x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "x = layers.Dense(32, activation='relu')(x)\n",
    "output_tensor = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = Model(input_tensor, output_tensor)  # 입력과 출력 텐서를 지정하여 Model 클래스의 객체를 만듭니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a5833",
   "metadata": {},
   "source": [
    "관련되지 않은 입력과 출력으로 모델을 만들면 RuntimeError가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9495adf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Graph disconnected: cannot obtain value for tensor Tensor(\"input_1:0\", shape=(?, 64), dtype=float32) at layer \"input_1\". The following previous layers were accessed without issue: []",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-54197a8d0ec3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0munrelated_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbad_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munrelated_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\git\\jongkwangyun.github.io\\aikerasstudy\\aikeras\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m   1809\u001b[0m                                 \u001b[1;34m'The following previous layers '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1810\u001b[0m                                 \u001b[1;34m'were accessed without issue: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1811\u001b[1;33m                                 str(layers_with_complete_input))\n\u001b[0m\u001b[0;32m   1812\u001b[0m                     \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1813\u001b[0m                         \u001b[0mcomputable_tensors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Graph disconnected: cannot obtain value for tensor Tensor(\"input_1:0\", shape=(?, 64), dtype=float32) at layer \"input_1\". The following previous layers were accessed without issue: []"
     ]
    }
   ],
   "source": [
    "unrelated_input = Input(shape=(32,))\n",
    "bad_model = model = Model(unrelated_input, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e9bd0c",
   "metadata": {},
   "source": [
    "이 에러는 케라스가 출력 텐서에서 input_1 텐서로 다다를 수 없다는 뜻입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14e8f3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 5s 5ms/step - loss: 11.7756\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 55us/step - loss: 11.6057\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 54us/step - loss: 11.5846\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 84us/step - loss: 11.5745\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 56us/step - loss: 11.5680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 31us/step - loss: 11.5620\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 89us/step - loss: 11.5579\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 57us/step - loss: 11.5536\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 65us/step - loss: 11.5502\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 52us/step - loss: 11.5473\n",
      "1000/1000 [==============================] - 0s 74us/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')  # 모델을 컴파일합니다.\n",
    "import numpy as np  # 훈련을 위해 랜덤한 넘파이 데이터를 생성합니다..\n",
    "x_train = np.random.random((1000, 64))\n",
    "y_train = np.random.random((1000, 10))\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=128)  # 열 번 에포크 동안 모델을 훈련합니다.\n",
    "\n",
    "score = model.evaluate(x_train, y_train)  # 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24998512",
   "metadata": {},
   "source": [
    "### 7.1.2 다중 입력 모델\n",
    "\n",
    "함수형 API는 다중 입력 모델을 만드는 데 사용할 수 있습니다. 일반적으로 이런 모델은 서로 다른 입력 가지를 합치기 위해 여러 텐서를 연결할 수 있는 층을 사용합니다. 이와 관련된 케라스의 함수는 keras.layers.add, keras.layers.concatenate 등입니다. 아주 간단한 다중 입력 모델을 살펴보겠습니다. 질문-응답(question-answering) 모델입니다.\n",
    "\n",
    "전형적인 질문-응답 모델은 2개의 입력을 가집니다. 하나는 자연어 질문이고, 또 하나는 답변에 필요한 정보가 담겨 있는 텍스트(예를 들어 뉴스 기사)입니다.\n",
    "\n",
    "#### 코드 7-1 2개의 입력을 가진 질문-응답 모델의 함수형 API 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b55686be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "text_input = Input(shape=(None,), dtype='int32', name='text')  # 텍스트 입력은 길이가 정해지지 않은 정수 시퀀스입니다. 입력 이름을 지정할 수 있습니다.\n",
    "\n",
    "embedded_text = layers.Embedding(text_vocabulary_size, 64)(text_input)  # 입력을 크기가 64인 벡터의 시퀀스로 임베딩합니다.\n",
    "\n",
    "encoded_text = layers.LSTM(32)(embedded_text)  # LSTM을 사용하여 이 벡터들을 하나의 벡터로 인코딩합니다.\n",
    "\n",
    "question_input = Input(shape=(None,),\n",
    "                      dtype='int32',\n",
    "                      name='question')  # 질문도 동일한 과정을 거칩니다(층 객체는 다릅니다)\n",
    "\n",
    "embedded_question = layers.Embedding(question_vocabulary_size, 32)(question_input)\n",
    "encoded_question = layers.LSTM(16)(embedded_question)\n",
    "\n",
    "concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1)  # 인코딩된 질문과 텍스트를 연결합니다.\n",
    "\n",
    "answer = layers.Dense(answer_vocabulary_size, activation='softmax')(concatenated)  # 소프트맥스 분류기를 추가합니다.\n",
    "\n",
    "model = Model([text_input, question_input], answer)  # 모델 객체를 만들고 2개의 입력과 출력을 주입합니다.\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccac6b9",
   "metadata": {},
   "source": [
    "입력이 2개인 모델은 어떻게 훈련할까요? 두 가지 방식이 있습니다. 넘파이 배열의 리스트를 주입하거나 입력 이름과 넘파이 배열로 이루어진 딕셔너리를 모델의 입력으로 주입할 수 있습니다.\n",
    "\n",
    "#### 코드 7-2 다중 입력 모델에 데이터 주입하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa28a02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 6.2145 - acc: 1.0000e-03\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.1982 - acc: 0.0310\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.1415 - acc: 0.0070\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.0581 - acc: 0.0070\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 6.0003 - acc: 0.0070\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.9351 - acc: 0.0080\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.8553 - acc: 0.0120\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.7731 - acc: 0.0170\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.6932 - acc: 0.0190\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.6072 - acc: 0.0270\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.5547 - acc: 0.0220\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.4723 - acc: 0.0320\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.4148 - acc: 0.0470\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.3542 - acc: 0.0480\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.2909 - acc: 0.0510\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.2107 - acc: 0.0580\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 3s 3ms/step - loss: 5.1854 - acc: 0.0600\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.0954 - acc: 0.0800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.0681 - acc: 0.0880\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 5.0099 - acc: 0.0850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x206368bbba8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))  # 랜덤한 넘파이 데이터를 생성합니다.\n",
    "question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "answers = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "\n",
    "answers = to_categorical(answers)  # 답은 정수가 아닌 원-핫 인코딩된 벡터입니다.\n",
    "\n",
    "model.fit([text, question], answers, epochs=10, batch_size=128)  # 리스트 입력을 사용하여 학습합니다.\n",
    "\n",
    "model.fit({'text': text, 'question': question}, answers, epochs=10, batch_size=128)  # 딕셔너리 입력을 사용하여 학습합니다(입력 이름을 지정했을 때만 사용할 수 있습니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f06cfe",
   "metadata": {},
   "source": [
    "### 7.1.3 다중 출력 모델\n",
    "\n",
    "같은 식으로 함수형 API를 사용하여 다중 출력(또는 다중 머리) 모델을 만들 수 있습니다. 간단한 예는 데이터에 있는 여러 속성을 동시에 예측하는 네트워크입니다. 예를 들어 소셜 미디어에서 익명 사용자의 포스트를 입력으로 받아 그 사람의 나이, 성별, 소득 수준 등을 예측합니다.\n",
    "\n",
    "#### 코드 7-3 3개의 출력을 가진 함수형 API 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d83e75a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "posts_input = Input(shape=(None,), dtype='int32', name='posts')\n",
    "embedded_posts = layers.Embedding(vocabulary_size, 256)(posts_input)\n",
    "x = layers.Conv1D(128, 5, activation='relu')(embedded_posts)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.Conv1D(256, 5, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dense(128, activation='relu')(x)\n",
    "\n",
    "age_prediction = layers.Dense(1, name='age')(x)  # 출력 층에 이름을 지정합니다.\n",
    "income_prediction = layers.Dense(num_income_groups, activation='softmax', name='income')(x)\n",
    "gender_prediction = layers.Dense(1, activation='sigmoid', name='gender')(x)\n",
    "\n",
    "model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e69b0f",
   "metadata": {},
   "source": [
    "#### 코드 7-4 다중 출력 모델의 컴파일 옵션: 다중 손실"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7963b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'])\n",
    "\n",
    "# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.compile(optimizer='rmsprop', loss={'age': 'mse',\n",
    "                                        'income': 'categorical_crossentropy',\n",
    "                                        'gender': 'binary_crossentropy'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3abac",
   "metadata": {},
   "source": [
    "#### 코드 7-5 다중 출력 모델의 컴파일 옵션: 손실 가중치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2792b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss=['mse', 'categorical_crossentropy', 'binary_crossentropy'],\n",
    "             loss_weights=[0.25, 1., 10.])\n",
    "\n",
    "# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.compile(optimizer='rmsprop', loss={'age': 'mse',\n",
    "                                        'income': 'categorical_crossentropy',\n",
    "                                        'gender': 'binary_crossentropy'},\n",
    "             loss_weights={'age': 0.25,\n",
    "                          'income': 1.,\n",
    "                          'gender': 10.})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07581953",
   "metadata": {},
   "source": [
    "#### 코드 7-6 다중 출력 모델에 데이터 주입하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a14621a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'posts' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e5171cfe670a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mage_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgender_targets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# age_targets, income_targets, gender_targets 가 배열이라고 가정합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m model.fit(posts, {'age': age_targets,\n\u001b[0;32m      5\u001b[0m                  \u001b[1;34m'income'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mincome_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'posts' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)  # age_targets, income_targets, gender_targets 가 배열이라고 가정합니다.\n",
    "\n",
    "# 위와 동일합니다(출력 층에 이름을 지정했을 때만 사용할 수 있습니다).\n",
    "model.fit(posts, {'age': age_targets,\n",
    "                 'income': income_targets,\n",
    "                 'gender': gender_targets},\n",
    "         epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a171e73b",
   "metadata": {},
   "source": [
    "### 7.1.4 층으로 구성된 비순환 유향 그래프\n",
    "\n",
    "케라스의 신경망은 층으로 구성된 어떤 비순환 유향 그래프(directed acyclic graph)도 만들 수 있습니다. 이 그래프는 원형을 띨 수 없습니다. 텐서 x가 자기 자신을 출력하는 층의 입력이 될 수 없습니다.\n",
    "\n",
    "#### 인셉션 모듈\n",
    "네트워크 안의 네트워크(network-in-network) 구조\n",
    "```python\n",
    "from keras import layers\n",
    "branch_a = layers.Conv2D(128, 1, activation='relu', strides=2)(x)  # 모든 가지는 동일한 스트라이드(2)를 사용합니다. 출력 크기를 동일하게 만들어 하나로 합치기 위해서입니다.\n",
    "\n",
    "# 이 가지에서는 두 번째 합성곱 층에서 스트라이드를 적용합니다.\n",
    "branch_b = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_b = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_b)\n",
    "\n",
    "# 이 가지에서는 평균 풀링 층에서 스트라이드를 적용합니다.\n",
    "branch_c = layers.AveragePooling2D(3, strides=2)(x)\n",
    "branch_c = layers.Conv2D(128, 3, activation='relu')(branch_c)\n",
    "\n",
    "branch_d = layers.Conv2D(128, 1, activation='relu')(x)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu')(branch_d)\n",
    "branch_d = layers.Conv2D(128, 3, activation='relu', strides=2)(branch_d)\n",
    "output = layers.concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)  # 모든 가지의 출력을 연결하여 모듈의 출력을 만듭니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38209328",
   "metadata": {},
   "source": [
    "#### 잔차 연결\n",
    "대규모 딥러닝 모델에서 흔히 나타나는 두 가지 문제인 그래디언트 소실과 표현 병목(representational bottleneck)을 해결했습니다.\n",
    "\n",
    "잔차 연결은 하위 층의 출력을 상위 층의 입력으로 사용합니다.\n",
    "```python\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)  # x에 어떤 변환을 적용합니다.\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "\n",
    "y = layers.add([y, x])  # 원본 x를 출력 특성에 더합니다.\n",
    "```\n",
    "\n",
    "다음은 특성 맵의 크기가 다를 때 선형 변환을 사용하여 잔차 연결을 구현한 예입니다\n",
    "```python\n",
    "from keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(x)\n",
    "y = layers.Conv2D(128, 3, activation='relu', padding='same')(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding='same')(x)  # y와 크기를 맞추기 위해 1×1 합성곱을 사용하여 원본 텐서 x를 다운샘플링합니다.\n",
    "\n",
    "y = layers.add([y, residual])  # 다운샘플링된 x를 출력 특성에 더합니다.\n",
    "```\n",
    "\n",
    "### 7.1.5 층 가중치 공유\n",
    "\n",
    "함수형 API의 중요한 또 하나의 기능은 층 객체를 여러 번 재사용할 수 있다는 것입니다.\n",
    "\n",
    "```python\n",
    "from keras import layers\n",
    "from keras import Input\n",
    "from keras.models import Model\n",
    "\n",
    "lstm = layers.LSTM(32)  # LSTM 층 객체 하나를 만듭니다.\n",
    "# 모델의 왼쪽 가지를 구성합니다. 입력은 크기가 128인 벡터의 가변 길이 시퀀스입니다.\n",
    "left_input = Input(shape=(None, 128))\n",
    "left_output = lstm(left_input)\n",
    "\n",
    "# 모델의 오른쪽 가지를 구성합니다. 기존 층 객체를 호출하면 가중치가 재사용됩니다.\n",
    "right_input = Input(shape=(None, 128))\n",
    "right_output = lstm(right_input)\n",
    "\n",
    "# 맨 위에 분류기를 놓습니다.\n",
    "merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "predictions = layers.Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "# 모델 객체를 만들고 훈련합니다. 이런 모델을 훈련하면 LSTM 층의 가중치는 양쪽 입력을 바탕으로 업데이트됩니다.\n",
    "model = Model([left_input, right_input], predictions)\n",
    "model.fit([left_data, right_data], targets)\n",
    "```\n",
    "\n",
    "### 7.1.6 층과 모델\n",
    "\n",
    "함수형 API에서는 모델을 층처럼 사용할 수 있습니다. 이 말은 입력 텐서로 모델을 호출해서 출력 텐서를 얻을 수 있다는 뜻입니다.\n",
    "\n",
    "```y = model(x)```\n",
    "\n",
    "모델에서 입력 텐서와 출력 텐서가 여러 개이면 텐서의 리스트로 호출합니다.\n",
    "\n",
    "```y1, y2 = model([x1, x1])```\n",
    "\n",
    "모델 객체를 재사용하는 간단한 실전 예는 듀얼 카메라에서 입력을 받는 비전 모델입니다.\n",
    "\n",
    "```python\n",
    "from keras import layers\n",
    "from keras import applications\n",
    "from keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)  # 이미지 처리 기본 모델은 엑셉션 네트워크입니다(합성곱 기반 층만 사용합니다).\n",
    "# 입력은 250×250 RGB 이미지입니다.\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "#같으느 비전 모델을 두 번 호출합니다.\n",
    "left_features = xception_base(left_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)  # 합쳐진 특성은 오른쪽 입력과 왼쪽 입력에서 얻은 정보를 담고 있습니다.\n",
    "```\n",
    "\n",
    "### 7.1.7 정리\n",
    "이것으로 케라스의 함수형 API 소개를 마칩니다.\n",
    "- 차례대로 층을 쌓는 것 이상이 필요할 때는 Sequential API를 사용하지 않습니다.\n",
    "- 함수형 API를 사용하여 다중 입력, 다중 출력, 복잡한 네트워크 토폴로지를 갖는 케라스 모델을 만드는 방법\n",
    "- 다른 네트워크 가지에서 같은 층이나 모델 객체를 여러 번 호출하여 가중치를 재사용하는 방법"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
