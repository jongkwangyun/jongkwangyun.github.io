{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3625f09",
   "metadata": {},
   "source": [
    "# 9.1 핵심 개념 리뷰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2918fe13",
   "metadata": {},
   "source": [
    "### 9.1.1 AI를 위한 여러 방법\n",
    "\n",
    "인공지능은 역사가 깊고 광범위한 분야로 일반적으로 인지 과정을 자동화하기 위한 모든 방법을 말합니다.\n",
    "\n",
    "머신 러닝은 훈련 데이터를 사용하여 자동으로 프로그램(모델이라고 부릅니다)을 개발하는 AI의 특정 하위 분야입니다.\n",
    "\n",
    "딥러닝은 머신 러닝의 여러 종류 중 하나입니다. 기하학적 변환 함수들이 번갈아 가며 연속적으로 길게 연결된 모델입니다.\n",
    "\n",
    "### 9.1.2 머신 러닝 분야에서 딥러닝이 특별한 이유\n",
    "\n",
    "불과 몇 년 만에 딥러닝이 역사적으로 컴퓨터에서 매우 어렵다고 인식된 다양한 종류의 문제에서 큰 성과를 거두었습니다.\n",
    "\n",
    "### 9.1.3 딥러닝에 대하여\n",
    "\n",
    "경사 하강법으로 충분히 큰 모수 모델(parametric model)을 충분히 많은 샘플에서 훈련하는 것이 필요한 전부라는 것을 압니다.\n",
    "\n",
    "딥러닝에서 모든 것은 벡터입니다.\n",
    "\n",
    "### 9.1.4 핵심 기술\n",
    "\n",
    "### 9.1.5 일반적인 머신러닝 작업흐름\n",
    "\n",
    "1. 문제를 정의합니다. 어떤 데이터를 사용할 수 있고 예측 대상은 무엇인가요? 데이터를 더 많이 모아야 하나요? 데이터셋에 레이블을 달기 위해 사람을 고용해야 하나요?\n",
    "2. 목표 달성을 측정하기 위해 신뢰할 수 있는 방법을 찾습니다. 간단한 작업이라면 예측 정확도가 될 수 있지만 많은 경우에 문제 영역에 특화된 정교한 지표가 필요합니다.\n",
    "3. 모델을 평가하기 위해 사용할 검증 과정을 준비합니다. 특별히 훈련 세트, 검증 세트, 테스트 세트를 정의해야 합니다. 검증 세트와 테스트 세트의 레이블은 훈련 데이터에 노출되어서는 안 됩니다. 예를 들어 시계열 예측의 경우 검증 데이터와 테스트 데이터는 시간 순서상 훈련 데이터 뒤에 와야 합니다.\n",
    "4. 데이터를 벡터화하고 신경망에 잘 맞는 형태로 전처리합니다(정규화 등).\n",
    "5. 상식 수준의 기본 모델보다 나은 첫 번째 모델을 만듭늬다. 머신 러닝이 주어진 문제를 해결할 수 있는지 확인합니다. 언제나 문제를 해결할 수 있지는 않습니다!\n",
    "6. 하이퍼파라미터를 튜닝하고 규제를 추가하여 모델 구조를 점진적으로 개선합니다. 테스트 데이터나 훈련 데이터를 사용하지 않고 검증 데이터의 성능만 사용하여 조정합니다. 모델이 과대적합(필요한 것보다 더 큰 용량의 모델을 만듭니다)된 후 규제를 추가하거나 모델의 크기를 줄입니다.\n",
    "7. 하이퍼파라미터 튜닝을 하면 검증 세트에 과대적합된다는 것을 유념하세요. 하이퍼파라미터가 검증 세트에 지나치게 특화될 수 있습니다. 이 때문에 테스트 세트를 따로 떼어 놓았습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b2100",
   "metadata": {},
   "source": [
    "### 9.1.6 주요 네트워크 구조\n",
    "\n",
    "- 벡터 데이터: 완전 연결 네트워크(Dense 층)\n",
    "- 이미지 데이터: 2D 컨브 넷\n",
    "- 사운드 데이터(예를 들어 파형 데이터): 1D 컨브넷(권장)이나 RNN\n",
    "- 텍스트 데이터: 1D 컨브넷(권장)이나 RNN\n",
    "- 시계열 데이터: RNN(권장)이나 1D 컨브넷\n",
    "- 다른 종류의 시퀀스 데이터: RNN이나 1D 컨브넷. 데이터 순서에 중요한 의미가 있다면 RNN이 낫습니다(예를 들어 시계열 데이터의 경우, 하지만 텍스트의 경우는 아닙니다).\n",
    "- 비디오 데이터: 3D 컨브넷(연속 동작을 감지할 필요가 있다면)이나 특성 추출을 담당하는 프레임별 2D 컨브넷과 그 뒤를 이어 시퀀스를 처리하는 RNN이나 1D 컨브넷의 조합입니다.\n",
    "- 볼륨을 가진 데이터: 3D 컨브넷\n",
    "\n",
    "#### 완전 연결 네트워크\n",
    "\n",
    "완전 연결 네트워크는 벡터 데이터(벡터의 배치)를 처리하는 Dense 층을 쌓은 것입니다. 한 Dense 층의 유닛이 다른 층의 모든 유닛과 연결되어 있기 때문에 완전 연결이라고 부릅니다.\n",
    "\n",
    "이진 분류를 수행하려면 마지막 Dense 층이 하나의 유닛을 가져야 하고 시그모이드 활성화 함수를 사용해야 합니다. 손실은 binary_crossentropy를 사용합니다. 타깃은 0 또는 1이 됩ㄴ다.\n",
    "\n",
    "```python\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "```\n",
    "\n",
    "단일 레이블 다중 분류를 수행하려면 마지막 Dense 층이 클래스 개수만큼 유닛을 가져야 하고 softmax 활성화 함수를 사용해야 합니다. 타깃을 원-핫 인코딩한다면 categorical_crossentropy를 손실로 사용합니다. 타깃이 정수 숫자라면 sparse_categorical_crossentropy를 손실로 사용합니다.\n",
    "\n",
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3da2a6",
   "metadata": {},
   "source": [
    "다중 레이블 다중 분류를 수행하려면 마지막 Dense 층이 클래스 개수만큼 유닛을 가져야 하고 시그모이드 활성화 함수를 사용해야 합니다. 손실로는 binary_crossentropy를 사용합니다. 타깃은 k-핫 인코딩되어야 합니다.\n",
    "\n",
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "```\n",
    "\n",
    "연속된 값을 가진 벡터에 대해 회귀를 수행하려면 마지막 Dense 층이 예측하려는 값의 개수만큼 유닛을 가져야 하고 활성화 함수는 사용하지 않습니다. 회귀에는 여러가지 손실을 사용할 수 있습니다. 가장 널리 사용되는 것은 mean_squared_error(MSE)와 mean_absolute_error(MAE)입니다.\n",
    "\n",
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(num_input_features,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_values))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='mse')\n",
    "```\n",
    "\n",
    "#### 컨브넷\n",
    "\n",
    "컨브넷 또는 합성곱 네트워크는 합성곱과 최대 풀링 층이 쌓여 구성됩니다.\n",
    "\n",
    "다음은 전형적인 이미지 분류 네트워크입니다(여기에서는 다중 분류의 예입니다)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241ec388",
   "metadata": {},
   "source": [
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.SeparableConv2D(32, 3, activation='relu', input_shape=(height, width, channels)))\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "model.add(layers.SeparableConv2D(64, 3, activation='relu'))\n",
    "model.add(layers.SeparableConv2D(128, 3, activation='relu'))\n",
    "model.add(layers.GlobalAveragePooling2D())\n",
    "\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "```\n",
    "\n",
    "#### RNN\n",
    "\n",
    "순환 신경망(RNN)은 한 번에 하나의 타임스텝씩 입력 시퀀스를 처리하고 이 과정 동안 상태(state)를 유지합니다.\n",
    "\n",
    "케라스에는 3개의 RNN 층이 있습니다. SimpleRNN, GRU, LSTM입니다. 대부분의 실전 애플리케이션에는 GRU나 LSTM을 사용해야 합니다. LSTM이 더 강력하지만 비용이 많이 듭니다. GRU는 좀 더 간단하고 값싼 LSTM의 대체물로 생각할 수 있습니다.\n",
    "\n",
    "여러 개의 RNN 층을 겹겹이 쌓으려면 마지막 층 이전의 모든 층은 전체 시퀀스를 출력해야 합니다.\n",
    "\n",
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(32, input_shape=(num_timesteps, num_features)))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "```\n",
    "\n",
    "다음은 벡터 시퀀스의 이진 분류를 위해 RNN 층을 쌓은 모델입니다.\n",
    "\n",
    "```python\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(32, return_sequences=True, input_shape=(num_timesteps, num_features)))\n",
    "model.add(layers.LSTM(32, return_sequences=True))\n",
    "model.add(layers.LSTM(32))\n",
    "model.add(layers.Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e5b6da",
   "metadata": {},
   "source": [
    "### 9.1.7 딥러닝의 가능성"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
