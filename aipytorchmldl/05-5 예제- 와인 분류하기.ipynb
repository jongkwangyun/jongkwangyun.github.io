{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e7fc86",
   "metadata": {},
   "source": [
    "# 5-5 예제: 와인 분류하기\n",
    "\n",
    "## 학습 데이터 준비\n",
    "\n",
    "### 예제 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7181ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 라이브러리 임포트\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# scikit-learn 라이브러리 임포트\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pandas 라이브러리 임포트\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05038a8a",
   "metadata": {},
   "source": [
    "### 예제 5.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74645689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 와인 데이터 읽어 들이기\n",
    "wine = load_wine()\n",
    "wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f2ccae",
   "metadata": {},
   "source": [
    "사이킷런에 포함된 와인 데이터 집합을 학습 데이터로 사용할 것이다. 와인 데이터 집합을 읽어 들여 wine 변수에 저장한다. wine 변수에는 다음과 같은 필드가 담겨 있다.\n",
    "\n",
    "- DESCR: 데이터 집합의 상세 정보\n",
    "- data: 와인 성분 데이터(설명변수)\n",
    "- feature_names: 와인의 성분명\n",
    "- target: 와인의 품종 데이터(목적변수)\n",
    "- target_names: 와인의 품종 이름\n",
    "\n",
    "### 예제 5.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c959dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터프레임에 담긴 설명변수 출력\n",
    "pd.DataFrame(wine.data, columns=wine.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b674dc3",
   "metadata": {},
   "source": [
    "와인 성분 데이터(설명변수)를 먼저 확인해 보자. wine.data로 이 데이터에 접근할 수 있다.\n",
    "실행 결과를 옆으로 스크롤해보면 와인 성분 13가지를 확인할 수 있다.\n",
    "\n",
    "### 예제 5.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab111b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 목적변수 데이터 출력\n",
    "wine.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35955b21",
   "metadata": {},
   "source": [
    "이번에는 와인 품종 데이터(목적변수)를 확인해 보자. wine.target으로 이 데이터에 접근할 수 있다.\n",
    "\n",
    "### 예제 5.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91da5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수와 목적변수를 변수에 대입\n",
    "wine_data = wine.data[0:130]\n",
    "wine_target = wine.target[0:130]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6471e08d",
   "metadata": {},
   "source": [
    "목적변수의 값은 0~2까지 3가지이지만 이번에는 0과 1로 2가지로 제한한다. 설명변수와 목적변수 모두 앞에서부터 130건까지만 추려낸다.\n",
    "\n",
    "### 예제 5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3eff6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# 데이터 집합을 훈련 데이터와 테스트 데이터로 분할\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(wine_data, wine_target, test_size=0.2)\n",
    "\n",
    "# 데이터 건수 확인\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6a502",
   "metadata": {},
   "source": [
    "데이터 집합을 훈련 데이터와 테스트 데이터로 분할한다.\n",
    "\n",
    "## 텐서 생성\n",
    "\n",
    "준비가 끝난 데이터를 파이토치가 다룰 수 있는 형태로 정리한다.\n",
    "\n",
    "### 예제 5.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33ed2d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104, 13])\n",
      "torch.Size([104])\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "# 테스트 데이터 텐서 변환\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n",
    "\n",
    "# 텐서로 변환한 데이터 건수 확인\n",
    "print(train_X.shape)\n",
    "print(train_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908b373",
   "metadata": {},
   "source": [
    "이 책에서는 텐서라는 용어를 다차원 배열이라는 의미로 사용한다.\n",
    "\n",
    "텐서의 차원을 확인한다. 원래 데이터를 빠짐없이 변환했음을 확인했다.\n",
    "\n",
    "> **파이토치 함수**\n",
    ">```\n",
    ">torch.from_numpy(ndarray)\n",
    ">```\n",
    ">NumPy 배열을 텐서로 변환한다.\n",
    "\n",
    "### 예제 5.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdab2ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1.1640e+01, 2.0600e+00, 2.4600e+00, 2.1600e+01, 8.4000e+01, 1.9500e+00,\n",
      "        1.6900e+00, 4.8000e-01, 1.3500e+00, 2.8000e+00, 1.0000e+00, 2.7500e+00,\n",
      "        6.8000e+02]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "# 설명변수와 목적변수의 텐서를 합침\n",
    "train = TensorDataset(train_X, train_Y)\n",
    "\n",
    "# 텐서의 첫 번재 데이터 내용 확인\n",
    "print(train[0])\n",
    "\n",
    "# 미니배치로 분할\n",
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7767bdcb",
   "metadata": {},
   "source": [
    "설명변수와 목적변수의 텐서를 합쳐서 train이라는 이름으로 훈련 데이터 집합을 만든다.\n",
    "\n",
    "train에서 데이터 한 건을 꺼내보면 설명변수 13개와 목적변수 1개가 표시되므로 텐서의 집합이 만들어 진 것을 알 수 있다.\n",
    "\n",
    "미니배치 학습을 수행하기 위해 데이터 집합을 셔플링해서 16개 단위로 분할한다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.utils.data.TensorDataset(data_tensor, target_tensor)\n",
    ">```\n",
    ">설명변수와 목적변수를 합쳐 인덱스를 붙이고 하나의 데이터 집합으로 만든다.\n",
    ">\n",
    ">파라미터\n",
    ">- data_tensor(Tensor): 설명변수 텐서\n",
    ">- target_tensor(Tensor): 목적변수 텐서\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    ">```\n",
    ">데이터 집합을 원하는 크기의 미니배치로 나누어 읽어들인다.\n",
    ">\n",
    ">파라미터\n",
    ">- dataset(Dataset): 읽어 들일 데이터 집합\n",
    ">- batch_size(int, optional): 배치 크긔, 기본값은 1\n",
    ">- shuffle(bool, optional): 각 에포크마다 데이터를 셔플링할지 여부, 기본값은 False.\n",
    "\n",
    "## 신경망 구성\n",
    "\n",
    "이제 학습에 사용할 신경망을 구성할 차례다. 그림 5.21과 같이 입력층, 중간층, 출력층이 하나씩 있는 신경망을 구성한다. 입력층의 노드 수는 13개(설명변수의 개수)이고, 중간층 노드의 수는 96개, 출력층 노드의 수는 2개(목적변수의 개수)다.\n",
    "\n",
    "### 예제 5.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8543d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 96)\n",
    "        self.fc2 = nn.Linear(96, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "# 인스턴스 생성\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b90a4",
   "metadata": {},
   "source": [
    "Net 클래스 안에 신경망을 구성한다. 생성자 메서드(데이터를 초기화하기 위한 함수)에서 입력층과 중간층 사이의 결합, 중간층과 출력층 사이의 결합, 그리고 각 층의 노드 수를 정의한다. forward 메서드에서는 활성화 함수를 정의하는데, 중간층에는 ReLU 함수를 사용하고 출력층은 소프트맥스 함수를 사용한다. 그다음 model이라는 이름으로 이 클래스의 인스턴스를 생성한다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.nn.Module\n",
    ">```\n",
    ">모든 신경망 모듈의 기본이 되는 클래스다. 이 클래스 안에 각 층과 함수, 신경망의 구조를 정의한다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.nn.Linear(in_features, out_features, bias=True)\n",
    ">```\n",
    ">입력 데이터에 대한 선형변환(y=Ax+b)을 계산한다.\n",
    ">\n",
    ">파라미터\n",
    ">- in_features: 입력 데이터의 차원 수\n",
    ">- out_features: 출력 데이터의 차원 수\n",
    ">- bias: 바이어스 학습 여부. 기본값은 True다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.nn.functional.relu(input)\n",
    ">```\n",
    ">ReLU 함수를 구현한 함수다.\n",
    ">\n",
    ">파라미터\n",
    ">- input: 입력 데이터\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.nn.functional.log_softmax(input)\n",
    ">```\n",
    ">로그 소프트맥스 함수를 구현한 함수다.\n",
    ">\n",
    ">파라미터\n",
    ">- input: 입력 데이터\n",
    "\n",
    "## 모형 학습\n",
    "\n",
    "앞서 3번째 단계에서 생성한 텐서를 조금 전에 만든 신경망에 입력해 모형을 학습해 본다. 그다음 학습된 모형의 정확도를 측정해 볼 것이다.\n",
    "\n",
    "### 예제 5.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96d3b282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\jongkwangyun.github.io\\aipytorchmldl\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 4.813330233097076\n",
      "100 4.801799237728119\n",
      "150 4.824586987495422\n",
      "200 4.838492214679718\n",
      "250 4.812598884105682\n",
      "300 4.813462555408478\n"
     ]
    }
   ],
   "source": [
    "# 오차함수 객체\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    # 분할해 둔 데이터를 꺼내옴\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산\n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    # 50회 반복마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf622195",
   "metadata": {},
   "source": [
    "교차엔트로피로 오차를 계산하는 오차함수의 인스턴스인 criterion을 생성한다. 확률적 경사하강법으로 가중치를 최적화하는 SGD 클래스의 인스턴스 optimizer를 생성한다.\n",
    "\n",
    "미니배치학습을 위해 분할해 둔 데이터를 train_loader에서 꺼낸 다음, 설명변수를 train_x, 목적변수를 train_y에 저장해 계산 그래프를 구성한다. 그다음 순전파 계산을 끝내고 그 결과를 다시 output에 저장한다. 목적변수와 출력의 오차를 계산해서 loss에 저장하고, 역전파 계산으로 경사(기울기)계산 및 가중치를 업데이트 한다. 그리고 이 과정을 300번 반복해 학습을 마친다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.nn.CrossEntropy\n",
    ">```\n",
    ">교차 엔트로피 함수를 구현한 클래스다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.optim.SGD(params, lr=<object object>)\n",
    ">```\n",
    ">확률적 경사 하강법을 구현한 클래스다.\n",
    ">\n",
    ">파라미터\n",
    ">- params: 최적화 대상이 될 파라미터 그룹을 정의\n",
    ">- lr: 학습률\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.autograd.Variable(data)\n",
    ">```\n",
    ">텐서를 래핑하고, 계산과정을 기록하는 역할을 한다.\n",
    ">\n",
    ">파라미터\n",
    ">- data: 입력할 텐서\n",
    "    \n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.autograd.backward(variables)\n",
    ">```\n",
    ">경사의 합을 구한다.\n",
    ">\n",
    ">파라미터\n",
    ">- variables: 입력 변수\n",
    "\n",
    "이 코드를 실행하면 저 위와 같은 결과가 표시되므로 오차가 수렴해 가는 것을 알 수 있다.\n",
    "    \n",
    "### 예제 5.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f782227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\git\\jongkwangyun.github.io\\aipytorchmldl\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5384615384615384"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "# 출력이 0 혹은 1이 되게 함\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fabe7",
   "metadata": {},
   "source": [
    "이번에는 테스트 데이터의 설명변수를 test_x, 목적변수를 test_Y로 저장해서 계산 그래프를 구성한다. 그리고 목적변수의 값과 순전파 출력값 중 최곳값을 result에 저장한다. 모형의 정확도는 전체 건수에서 목적변수 test_y와 result가 일치한 건수의 비율을 기준으로 한다.\n",
    "\n",
    "필자의 환경에서 모형의 정확도는 0.65384가 나왔다. 다시말해, 약 65%의 정확도로 와인의 종류를 정확하게 분류했다. 이번에는 데이터 건수의 모수가 적기 때문에 정확도가 65%에 미치지 못하는 경우가 있을 수 있다.\n",
    "\n",
    ">**파이토치 함수**\n",
    ">```\n",
    ">torch.max(input)\n",
    ">```\n",
    ">입력 텐서의 최댓값을 반환한다.\n",
    ">- input: 입력 텐서"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
