{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af56022c-843b-4b9b-86ed-5aa3fec45714",
   "metadata": {},
   "source": [
    "# 2.3 사이킷런의 기반 프레임워크 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edafba6a-0cf7-4abb-922e-baae923d331f",
   "metadata": {},
   "source": [
    "## Estimator 이해 및 fit(), predict() 메서드\n",
    "사이킷런은 API 일관성과 개발 편의성을 제공하기 위한 노력이 엿보이는 패키지입니다. 사이킷런은 ML 모델 학습을 위해서 fit()을, 학습도니 모델의 예측을 위해 predict() 메서드를 제공합니다. 지도학습의 주요 두 축인 분류(Classification)와 회귀(Regression)의 다양한 알고리즘을 구현한 모든 사이킷런 클래스는 fit()과 predict()만을 이용해 간단하게 학습과 예측 결과를 반환합니다. 사이킷런은 매우 많은 유형의 Classifier와 Regressor 클래스를 제공합니다. 이들을 합쳐서 Estimator 클래스라고 부릅니다. Estimator 클래스는 fit()과 predict()를 내부에서 구현하고 있습니다.\n",
    "\n",
    "- Estimator\n",
    "  - Classifier\n",
    "    - DecisionTressClassifier\n",
    "    - RandomForestClassifier\n",
    "    - GradientBoostingClassifier\n",
    "    - GaussianNB\n",
    "    - SVC\n",
    "  - Regressor\n",
    "    - LinearRegression\n",
    "    - Ridge\n",
    "    - Lasso\n",
    "    - RandomForestRegressor\n",
    "    - GradientBoostingRegressor\n",
    "\n",
    "사이킷런에서 비지도 학습인 차원 축소, 클러스터링, 피처 추출(Feature Extraction) 등을 구현한 클래스 역시 대부분 fit()과 transform()을 적용합니다. fit()으로 변환을 위한 사전 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등의 실제 작업은 transform()으로 수행합니다. 사이킷런은 fit()과 transform()을 하나로 결합한 fit_transform()도 함께 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03099d0-17f8-486f-b293-5a8386bd68f0",
   "metadata": {},
   "source": [
    "## 사이킷런의 주요 모듈\n",
    "#### 분류나 회귀 연습용 예제 데이터\n",
    "|분류|모듈명|설명|\n",
    "|---|---|---|\n",
    "|예제 데이터|sklearn.datasets|사이킷런에 내장되어 예제로 제공하는 데이터 세트|\n",
    "|피처 처리|sklearn.preprocessing|데이터 전처리에 필요한 다양한 가공 기능 제공(문자열을 숫자형 코드 값으로 인코딩, 정규화, 스케일링 등)|\n",
    "||sklearn.feature_selection|알고리즘에 큰 영향을 미치는 피처를 우선순위대로 셀렉션 작업을 수행하는 다양한 기능 제공|\n",
    "||sklearn.feature_extraction|텍스트 데이터나 이미지 데이터의 벡터화된 피처를 추출하는데 사용됨.<br>예를 들어 텍스트 데이터에서 Count Vectorizer나 Tf-ldf Vectorizer 등을 생성하는 기능 제공.<br>텍스트 데이터의 피처 추출은 sklearn.feature_extraction.text 모듈에, 이미지 데이터의 피처 추출은 sklearn.feature_extraction.image 모듈에 지원 API가 있음.|\n",
    "|피처 처리 & 차원 축소|sklearn.decomposition|차원 축소와 관련한 알고리즘을 지원하는 모듈임. PCA, NMF, Truncated SVD 등을 통해 차원 축소 기능을 수행할 수 있음|\n",
    "|데이터 분리, 검증 & 파라미터 튜닝|sklearn.model_selection|교차 검증을 위한 학습용/테스트용 분리, 그리드 서치(Grid Search)로 최적 파라미터 추출 등의 API 제공|\n",
    "|평가|sklearn.metrics|분류, 회귀, 클러스터링, 페어와이즈(Pairwise)에 대한 다양한 성능 측정 방법 제공.<br>Accuracy, Precision, Recall, ROC-AUC, RMSE 등 제공|\n",
    "|ML 알고리즘|sklearn.ensemble|앙상블 알고리즘 제공<br>랜덤 포레스트, 에이다 부스트, 그래디언트 부스팅 등을 제공|\n",
    "||sklearn.linear_model|주로 선형 회귀, 릿지(Ridge), 라쏘(Lasso) 및 로지스틱 회귀 등 회귀 관련 알고리즘을 지원. 또한 SGD(Stochastic Gradient Descent) 관련 알고리즘도 제공|\n",
    "||sklearn.naive_bayes|나이브 베이즈 알고리즘 제공. 가우시안 NB, 다항 분포 NB 등|\n",
    "||sklearn.neighbors|최근접 이웃 알고리즘 제공. K-NN 등|\n",
    "||sklearn.svm|서포트 벡터 머신 알고리즘 제공|\n",
    "||sklearn.cluster|비지도 클러스터링 알고리즘 제공<br>(K-평균, 계층형, DBSCAN 등)|\n",
    "|유틸리티|sklearn.pipeline|피처 처리 등의 변환과 ML 알고리즘 학습, 예측 등을 함께 묶어서 실행할 수 있는 유틸리티 제공|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c2e5d-3063-46dc-a8fa-63ac7de50b15",
   "metadata": {},
   "source": [
    "일반적으로 머신러닝 모델을 구축하는 주요 프로세스는 피처의 가공, 변경, 추출을 수행하는 피처 처리(feature processing), ML 알고리즘 학습/예측 수행, 그리고 모델 평가의 단계를 반복적으로 수행하는 것입니다.\n",
    "\n",
    "## 내장된 예제 데이터 세트\n",
    "|API 명|설명|\n",
    "|---|---|\n",
    "|datasets.load_boston()|회귀 용도이며, 미국 보스터의 집 피처들과 가격에 대한 데이터 세트|\n",
    "|datasets.load_breast_cancer()|분류 용도이며, 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트|\n",
    "|datasets.load_diabetes()|회귀 용도이며, 당뇨 데이터 세트|\n",
    "|datasets.load_digits()|분류 용도이며, 0에서 9까지 숫자의 이미지 픽셀 데이터 세트|\n",
    "datasets.load_iris()|분류 용도이며, 붓꽃에 대한 피처를 가진 데이터 세트|\n",
    "\n",
    "fetch 계열의 명령은 데이터의 크기가 커서 패키지에 처음부터 저장돼 있지 않고 인터넷에서 내려받아 홈 디렉터리 아래의 scikit_learn_data라는 서브 디렉터리에 저장한 후 추후 불러들이는 데이터입니다.\n",
    "- fetch_covtype(): 회귀 분석용 토지 조사 자료\n",
    "- fetch_20newsgroups(): 뉴스 그룹 텍스트 자료\n",
    "- fetch_olivetti_faces(): 얼굴 이미지 자료\n",
    "- fetch_lfw_people(): 얼굴 이미지 자료\n",
    "- fetch_lfw_pairs(): 얼굴 이미지 자료\n",
    "- fetch_rcv1(): 로이터 뉴스 말뭉치\n",
    "- fetch_mldata(): ML 웹사이트에서 다운로드\n",
    "\n",
    "#### 분류와 클러스터링을 위한 표본 데이터 생성기\n",
    "|API 명|설명|\n",
    "|---|---|\n",
    "|datasets.make_classifications()|분류를 위한 데이터 세트를 만듭니다. 특히 높은 상관도, 불필요한 속성 등의 노이즈 효과를 위한 데이터를 무작위로 생성해 줍니다.|\n",
    "|datasets.make_blobs()|클러스터링을 위한 데이터 세트를 무작위로 생성해 줍니다. 군집 지정 개수에 따라 여러 가지 클러스터링을 위한 데이터 세트를 쉽게 만들어 줍니다.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e04df8-eb80-4281-9fe3-ac081ffd7480",
   "metadata": {},
   "source": [
    "예제 데이터가 어떻게 구성돼 있는지 좀 더 살펴보겠습니다.\n",
    "- data는 피처의 데이터 세트를 가리킵니다.\n",
    "- target은 분류시 레이블 값, 회귀일 때는 숫자 결괏값 데이터 세트입니다.\n",
    "- target_names는 개별 레이블의 이름을 나타냅니다.\n",
    "- feature_names는 피처의 이름을 나타냅니다.\n",
    "- DESCR은 데이터 세트에 대한 설명과 각 피처의 설명을 나타냅니다.\n",
    "\n",
    "먼저 붓꽃 데이터 세트를 생성해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d8c45e-135e-45a5-9da1-3edb792f29fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils._bunch.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1854f4c3-5450-4ca9-809b-a55380db74bc",
   "metadata": {},
   "source": [
    "Bunch 클래스는 파이썬 딕셔너리 자료형과 유사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "095e9184-3329-4c1b-a065-aaf8cec47f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print('붓꽃 데이터 세트의 키들:', keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59437ce-1d24-477a-97c2-514cc369b925",
   "metadata": {},
   "source": [
    "데이터 키는 피처들의 데이터 값을 가리킵니다. 데이터 세트가 딕셔너리 형태이기 때문에 피처 데이터 값을 추출하기 위해서는 데이터 세트.data(또는 데이터 세트['data'])를 이용하면 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b198f1ff-ea5a-40dc-b52b-92625738709f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names 의 type: <class 'list'>\n",
      " feature_names 의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 type: <class 'numpy.ndarray'>\n",
      " target_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data 의 type: <class 'numpy.ndarray'>\n",
      " data 의 shape: (150, 4)\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " target 의 type: <class 'numpy.ndarray'>\n",
      " target 의 shape: (150,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "print('\\n feature_names 의 type:', type(iris_data.feature_names))\n",
    "print(' feature_names 의 shape:', len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 type:', type(iris_data.target_names))\n",
    "print(' target_names의 shape:', len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data 의 type:', type(iris_data.data))\n",
    "print(' data 의 shape:', iris_data.data.shape)\n",
    "print(iris_data['data'])\n",
    "\n",
    "print('\\n target 의 type:', type(iris_data.target))\n",
    "print(' target 의 shape:', iris_data.target.shape)\n",
    "print(iris_data.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
